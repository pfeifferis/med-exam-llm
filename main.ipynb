{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import anthropic\n",
    "import google.generativeai as genai\n",
    "\n",
    "import PIL.Image\n",
    "import base64\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_gpt = OpenAI()\n",
    "claude = anthropic.Anthropic()\n",
    "#genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))\n",
    "#gemini = genai.GenerativeModel('gemini-pro-vision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_png_to_jpeg(png_path, jpeg_path):\n",
    "    img = PIL.Image.open(png_path)\n",
    "    rgb_img = img.convert('RGB')\n",
    "    rgb_img.save(jpeg_path, 'JPEG')\n",
    "    \n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def lanuage_models(system_text, user_text, image, max_tokens=1024):\n",
    "    \"\"\"\n",
    "    Generates responses from multiple language models based on the given system text, user text, and image.\n",
    "\n",
    "    Args:\n",
    "        system_text (str): The system text to provide context for the conversation.\n",
    "        user_text (str): The user text representing the user's input.\n",
    "        image (str): The path to the image file.\n",
    "        max_tokens (int, optional): The maximum number of tokens to generate in the response. Defaults to 1024.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the responses from different language models.\n",
    "            - chat_gpt_response (str): The response generated by the OpenAI GPT-4 Turbo model.\n",
    "            - claude_response (str): The response generated by the Anthropic Claude model.\n",
    "            - gemini_response (str): The response generated by the Google Gemini model.\n",
    "    \"\"\"\n",
    "    convert_png_to_jpeg(image+'.png', image+'.jpeg')\n",
    "    \n",
    "    base64_image = encode_image(image+'.jpeg')\n",
    "    pil_image = PIL.Image.open(image+'.jpeg')\n",
    "    \n",
    "    # openai\n",
    "    response = chat_gpt.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        max_tokens=max_tokens,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_text},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": user_text\n",
    "                },\n",
    "                {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                }\n",
    "                }]}],\n",
    "            \n",
    "    )\n",
    "    \n",
    "    chat_gpt_response = response.choices[0].message.content\n",
    "    \n",
    "    # anthropic\n",
    "    response = claude.messages.create(\n",
    "        model=\"claude-3-opus-20240229\",\n",
    "        max_tokens=max_tokens,\n",
    "        system=system_text,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"image\",\n",
    "                        \"source\": {\n",
    "                            \"type\": \"base64\",\n",
    "                            \"media_type\": \"image/jpeg\",\n",
    "                            \"data\": base64_image,\n",
    "                        },\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": user_text\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    claude_response = response.content[0].text\n",
    "    \n",
    "    # google\n",
    "    #response = gemini.generate_content([system_text+ ' ' +user_text, pil_image], stream=True)\n",
    "    gemini_response = 'X'#response.text\n",
    "    \n",
    "    return chat_gpt_response, claude_response, gemini_response\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_text = 'Stelle dir vor, dass du der beste deutschsprachige Medizinstudent bist. Du möchtest dein medizinisches Staatsexamen exzellent absolvieren! Nachfolgende werden dir Staatsexamina Fragen präsentiert. Gib als Lösung nur den richtigen Antwortbuchstaben aus!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/dgw9qr6x53qb0klsv8fjtnc40000gn/T/ipykernel_46029/886374425.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop([50,51,52,53,54], inplace=True)\n",
      "/var/folders/9n/dgw9qr6x53qb0klsv8fjtnc40000gn/T/ipykernel_46029/886374425.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['overall number'] = df['overall number'].astype(int)\n",
      "/var/folders/9n/dgw9qr6x53qb0klsv8fjtnc40000gn/T/ipykernel_46029/886374425.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={'overall number': 'id', 'total question ': 'question', 'correct answer': 'correct_answer'}, inplace=True)\n",
      "/var/folders/9n/dgw9qr6x53qb0klsv8fjtnc40000gn/T/ipykernel_46029/886374425.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.replace({'case': '-'}, float('NaN'), inplace=True)\n",
      "/var/folders/9n/dgw9qr6x53qb0klsv8fjtnc40000gn/T/ipykernel_46029/886374425.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.replace('NaN', np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_excel('data/questions.xlsx', sheet_name='AMBOSS - image')\n",
    "df = df_raw[['overall number', 'total question ', 'case', 'correct answer']]\n",
    "df.drop([50,51,52,53,54], inplace=True)\n",
    "df['overall number'] = df['overall number'].astype(int)\n",
    "df.rename(columns={'overall number': 'id', 'total question ': 'question', 'correct answer': 'correct_answer'}, inplace=True)\n",
    "df.replace({'case': '-'}, float('NaN'), inplace=True)\n",
    "df.replace('NaN', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:26<00:00, 13.03s/it]\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(columns=['id', 'correct_response', 'chat_gpt_response', 'claude_response', 'gemini_response'])\n",
    "\n",
    "for id in tqdm(range(1, 3)):\n",
    "    if df['case'][df['id'] == id].notna().all(): \n",
    "        user_text = df['case'][df['id'] == id].values[0] + df['question'][df['id'] == id].values[0]\n",
    "    else:\n",
    "        user_text = df['question'][df['id'] == id].values[0]\n",
    "        \n",
    "    chat_gpt_response, claude_response, gemini_response = lanuage_models(system_text, user_text, f'data/images/Amboss_SURG_images_{id:02}', max_tokens=1024)\n",
    "    \n",
    "    results = results._append({'id': id, 'correct_response': df['correct_answer'][df['id'] == id].values[0], 'chat_gpt_response': chat_gpt_response, 'claude_response': claude_response, 'gemini_response': gemini_response}, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>correct_response</th>\n",
       "      <th>chat_gpt_response</th>\n",
       "      <th>claude_response</th>\n",
       "      <th>gemini_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>B) arteriosklerotische pAVK</td>\n",
       "      <td>Die CT-Angiographie der unteren Extremitäten z...</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>E</td>\n",
       "      <td>B) linksseitiges Pulmonalisaneurysma</td>\n",
       "      <td>Die Computertomografie des Thorax zeigt eine i...</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id correct_response                     chat_gpt_response  \\\n",
       "0  1                B           B) arteriosklerotische pAVK   \n",
       "1  2                E  B) linksseitiges Pulmonalisaneurysma   \n",
       "\n",
       "                                     claude_response gemini_response  \n",
       "0  Die CT-Angiographie der unteren Extremitäten z...               X  \n",
       "1  Die Computertomografie des Thorax zeigt eine i...               X  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_excel('results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['id', 'correct_response' 'chat_gpt_response', 'claude_response', 'gemini_response'])\n",
    "\n",
    "for id in df['id']:\n",
    "    if df['case'][df['id'] == id].notna().all(): \n",
    "        user_text = df['case'][df['id'] == id].values[0] + df['question'][df['id'] == id].values[0]\n",
    "    else:\n",
    "        user_text = df['question'][df['id'] == id].values[0]\n",
    "        \n",
    "    chat_gpt_response, claude_response, gemini_response = lanuage_models(system_text, user_text, f'data/images/Amboss_SURG_images_{id:02}', max_tokens=1024)\n",
    "    \n",
    "    results.append({'id': id, 'correct_response': df['correct_response'][df['id'] == id].values[0], 'chat_gpt_response': chat_gpt_response, 'claude_response': claude_response, 'gemini_response': gemini_response}, ignore_index=True)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "med-exam-llm-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
