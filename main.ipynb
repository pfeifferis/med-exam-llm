{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import anthropic\n",
    "import google.generativeai as genai\n",
    "\n",
    "import PIL.Image\n",
    "import base64\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_gpt = OpenAI()\n",
    "claude = anthropic.Anthropic()\n",
    "#genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))\n",
    "#gemini = genai.GenerativeModel('gemini-pro-vision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_png_to_jpeg(png_path, jpeg_path):\n",
    "    img = PIL.Image.open(png_path)\n",
    "    rgb_img = img.convert('RGB')\n",
    "    rgb_img.save(jpeg_path, 'JPEG')\n",
    "    \n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def lanuage_models(system_text, user_text, image, max_tokens=1024):\n",
    "    \"\"\"\n",
    "    Generates responses from multiple language models based on the given system text, user text, and image.\n",
    "\n",
    "    Args:\n",
    "        system_text (str): The system text to provide context for the conversation.\n",
    "        user_text (str): The user text representing the user's input.\n",
    "        image (str): The path to the image file.\n",
    "        max_tokens (int, optional): The maximum number of tokens to generate in the response. Defaults to 1024.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the responses from different language models.\n",
    "            - chat_gpt_response (str): The response generated by the OpenAI GPT-4 Turbo model.\n",
    "            - claude_response (str): The response generated by the Anthropic Claude model.\n",
    "            - gemini_response (str): The response generated by the Google Gemini model.\n",
    "    \"\"\"\n",
    "    convert_png_to_jpeg(image+'.png', image+'.jpeg')\n",
    "    \n",
    "    base64_image = encode_image(image+'.jpeg')\n",
    "    pil_image = PIL.Image.open(image+'.jpeg')\n",
    "    \n",
    "    # openai\n",
    "    response = chat_gpt.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        max_tokens=max_tokens,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_text},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": user_text\n",
    "                },\n",
    "                {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                }\n",
    "                }]}],\n",
    "            \n",
    "    )\n",
    "    \n",
    "    chat_gpt_response = response.choices[0]\n",
    "    \n",
    "    # anthropic\n",
    "    response = claude.messages.create(\n",
    "        model=\"claude-3-opus-20240229\",\n",
    "        max_tokens=max_tokens,\n",
    "        system=system_text,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"image\",\n",
    "                        \"source\": {\n",
    "                            \"type\": \"base64\",\n",
    "                            \"media_type\": \"image/jpeg\",\n",
    "                            \"data\": base64_image,\n",
    "                        },\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": user_text\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    claude_response = response.content\n",
    "    \n",
    "    # google\n",
    "    #response = gemini.generate_content([system_text+ ' ' +user_text, pil_image], stream=True)\n",
    "    gemini_response = 'X'#response.text\n",
    "    \n",
    "    return chat_gpt_response, claude_response, gemini_response\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_text = 'Stelle dir vor, dass du der beste deutschsprachige Medizinstudent bist. Du möchtest dein medizinisches Staatsexamen exzellent absolvieren! Nachfolgende werden dir Staatsexamina Fragen präsentiert. Gib als Lösung nur den richtigen Antwortbuchstaben aus!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/dgw9qr6x53qb0klsv8fjtnc40000gn/T/ipykernel_46029/886374425.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop([50,51,52,53,54], inplace=True)\n",
      "/var/folders/9n/dgw9qr6x53qb0klsv8fjtnc40000gn/T/ipykernel_46029/886374425.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['overall number'] = df['overall number'].astype(int)\n",
      "/var/folders/9n/dgw9qr6x53qb0klsv8fjtnc40000gn/T/ipykernel_46029/886374425.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={'overall number': 'id', 'total question ': 'question', 'correct answer': 'correct_answer'}, inplace=True)\n",
      "/var/folders/9n/dgw9qr6x53qb0klsv8fjtnc40000gn/T/ipykernel_46029/886374425.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.replace({'case': '-'}, float('NaN'), inplace=True)\n",
      "/var/folders/9n/dgw9qr6x53qb0klsv8fjtnc40000gn/T/ipykernel_46029/886374425.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.replace('NaN', np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_excel('data/questions.xlsx', sheet_name='AMBOSS - image')\n",
    "df = df_raw[['overall number', 'total question ', 'case', 'correct answer']]\n",
    "df.drop([50,51,52,53,54], inplace=True)\n",
    "df['overall number'] = df['overall number'].astype(int)\n",
    "df.rename(columns={'overall number': 'id', 'total question ': 'question', 'correct answer': 'correct_answer'}, inplace=True)\n",
    "df.replace({'case': '-'}, float('NaN'), inplace=True)\n",
    "df.replace('NaN', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9n/dgw9qr6x53qb0klsv8fjtnc40000gn/T/ipykernel_46029/1455417411.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0muser_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mchat_gpt_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclaude_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgemini_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlanuage_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msystem_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'data/images/Amboss_SURG_images_{id:02}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'correct_response'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'correct_response'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'chat_gpt_response'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mchat_gpt_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'claude_response'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclaude_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gemini_response'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgemini_response\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/coding/med-exam-llm/med-exam-llm-venv/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6296\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(columns=['id', 'correct_response' 'chat_gpt_response', 'claude_response', 'gemini_response'])\n",
    "\n",
    "for id in range(1, 2):\n",
    "    if df['case'][df['id'] == id].notna().all(): \n",
    "        user_text = df['case'][df['id'] == id].values[0] + df['question'][df['id'] == id].values[0]\n",
    "    else:\n",
    "        user_text = df['question'][df['id'] == id].values[0]\n",
    "        \n",
    "    chat_gpt_response, claude_response, gemini_response = lanuage_models(system_text, user_text, f'data/images/Amboss_SURG_images_{id:02}', max_tokens=1024)\n",
    "    \n",
    "    results.append({'id': id, 'correct_response': df['correct_response'][df['id'] == id].values[0], 'chat_gpt_response': chat_gpt_response, 'claude_response': claude_response, 'gemini_response': gemini_response}, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TextBlock(text='Basierend auf der CT-Angiografie der unteren Extremitäten zeigt sich eine starke Kalzifizierung der arteriellen Gefäße, insbesondere der distalen Gefäßabschnitte. Dieses Verteilungsmuster mit Betonung der peripheren Arterien ist am ehesten vereinbar mit einer Kalziphylaxie (Antwort D).\\n\\nDie anderen Differentialdiagnosen sind weniger wahrscheinlich:\\n- Ein infrarenales Aortenaneurysma (A) würde sich im Bereich der Aorta und nicht so ausgeprägt peripher darstellen.  \\n- Eine arteriosklerotische pAVK (B) zeigt eher proximale Stenosen und Verschlüsse.\\n- Eine Calcinosis cutis (C) betrifft primär das subkutane Fettgewebe, nicht die Arterien.\\n- Eine arterielle Embolie (E) imponiert als akuter Gefäßverschluss, nicht als diffuse Verkalkung.', type='text')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claude_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['id', 'correct_response' 'chat_gpt_response', 'claude_response', 'gemini_response'])\n",
    "\n",
    "for id in df['id']:\n",
    "    if df['case'][df['id'] == id].notna().all(): \n",
    "        user_text = df['case'][df['id'] == id].values[0] + df['question'][df['id'] == id].values[0]\n",
    "    else:\n",
    "        user_text = df['question'][df['id'] == id].values[0]\n",
    "        \n",
    "    chat_gpt_response, claude_response, gemini_response = lanuage_models(system_text, user_text, f'data/images/Amboss_SURG_images_{id:02}', max_tokens=1024)\n",
    "    \n",
    "    results.append({'id': id, 'correct_response': df['correct_response'][df['id'] == id].values[0], 'chat_gpt_response': chat_gpt_response, 'claude_response': claude_response, 'gemini_response': gemini_response}, ignore_index=True)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "med-exam-llm-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
